{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "\n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "            # set 'self' node as inbound_nodes's outbound_nodes\n",
    "\n",
    "        self.value = None\n",
    "\n",
    "        self.gradients = {}\n",
    "        # keys are the inputs to this node, and their\n",
    "        # values are the partials of this node with \n",
    "        # respect to that input.\n",
    "        # \\partial{node}{input_i}\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        '''\n",
    "        Forward propagation. \n",
    "        Compute the output value vased on 'inbound_nodes' and store the \n",
    "        result in self.value\n",
    "        '''\n",
    "\n",
    "        raise NotImplemented\n",
    "    \n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        raise NotImplemented\n",
    "        \n",
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        An Input node has no inbound nodes.\n",
    "        So no need to pass anything to the Node instantiator.\n",
    "        '''\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self, value=None):\n",
    "        '''\n",
    "        Only input node is the node where the value may be passed\n",
    "        as an argument to forward().\n",
    "        All other node implementations should get the value of the \n",
    "        previous node from self.inbound_nodes\n",
    "        \n",
    "        Example: \n",
    "        val0: self.inbound_nodes[0].value\n",
    "        '''\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "            ## It's is input node, when need to forward, this node initiate self's value.\n",
    "\n",
    "        # Input subclass just holds a value, such as a data feature or a model parameter(weight/bias)\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {self:0}\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1\n",
    "            \n",
    "        \n",
    "        # input N --> N1, N2\n",
    "        # \\partial L / \\partial N \n",
    "        # ==> \\partial L / \\partial N1 * \\ partial N1 / \\partial N\n",
    "\n",
    "\n",
    "class Add(Node):\n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))\n",
    "        ## when execute forward, this node caculate value as defined.\n",
    "\n",
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "\n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "        \n",
    "    def backward(self):\n",
    "\n",
    "        # initial a partial for each of the inbound_nodes.\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            # Get the partial of the cost w.r.t this node.\n",
    "            grad_cost = n.gradients[self]\n",
    "\n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)\n",
    "\n",
    "        # WX + B / W ==> X\n",
    "        # WX + B / X ==> W\n",
    "\n",
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1./(1 + np.exp(-1 * x))\n",
    "\n",
    "    def forward(self):\n",
    "        self.x = self.inputs[0].value\n",
    "        self.value = self._sigmoid(self.x)\n",
    "\n",
    "    def backward(self):\n",
    "        self.partial = self._sigmoid(self.x) * (1 - self._sigmoid(self.x))\n",
    "        \n",
    "        # y = 1 / (1 + e^-x)\n",
    "        # y' = 1 / (1 + e^-x) (1 - 1 / (1 + e^-x))\n",
    "        \n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]  # Get the partial of the cost with respect to this node.\n",
    "\n",
    "            self.gradients[self.inputs[0]] = grad_cost * self.partial\n",
    "            # use * to keep all the dimension same!.\n",
    "\n",
    "\n",
    "\n",
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        Node.__init__(self, [y, a])\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        a = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert(y.shape == a.shape)\n",
    "\n",
    "        self.m = self.inputs[0].value.shape[0]\n",
    "        self.diff = y - a\n",
    "\n",
    "        self.value = np.mean(self.diff**2)\n",
    "\n",
    "\n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff\n",
    "\n",
    "\n",
    "def forward_and_backward(outputnode, graph):\n",
    "    # execute all the forward method of sorted_nodes.\n",
    "\n",
    "    ## In practice, it's common to feed in mutiple data example in each forward pass rather than just 1. Because the examples can be processed in parallel. The number of examples is called batch size.\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "        ## each node execute forward, get self.value based on the topological sort result.\n",
    "\n",
    "    for n in  graph[::-1]:\n",
    "        n.backward()\n",
    "\n",
    "    #return outputnode.value\n",
    "\n",
    "###   v -->  a -->  C\n",
    "##    b --> C\n",
    "##    b --> v -- a --> C\n",
    "##    v --> v ---> a -- > C\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "    `feed_dict`: A dictionary where the key is a `Input` node and the value is the respective value feed to that node.\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "            ## if n is Input Node, set n'value as \n",
    "            ## feed_dict[n]\n",
    "            ## else, n's value is caculate as its\n",
    "            ## inbounds\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def sgd_update(trainables, learning_rate=1e-2):\n",
    "    # there are so many other update / optimization methods\n",
    "    # such as Adam, Mom, \n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples = 506\n",
      "Epoch: 1, Loss: 136.582\n",
      "Epoch: 101, Loss: 6.581\n",
      "Epoch: 201, Loss: 5.802\n",
      "Epoch: 301, Loss: 5.007\n",
      "Epoch: 401, Loss: 3.898\n",
      "Epoch: 501, Loss: 4.510\n",
      "Epoch: 601, Loss: 3.523\n",
      "Epoch: 701, Loss: 4.123\n",
      "Epoch: 801, Loss: 4.534\n",
      "Epoch: 901, Loss: 3.737\n",
      "Epoch: 1001, Loss: 3.937\n",
      "Epoch: 1101, Loss: 4.296\n",
      "Epoch: 1201, Loss: 4.045\n",
      "Epoch: 1301, Loss: 4.403\n",
      "Epoch: 1401, Loss: 3.912\n",
      "Epoch: 1501, Loss: 3.839\n",
      "Epoch: 1601, Loss: 4.392\n",
      "Epoch: 1701, Loss: 3.884\n",
      "Epoch: 1801, Loss: 3.798\n",
      "Epoch: 1901, Loss: 4.551\n",
      "Epoch: 2001, Loss: 4.339\n",
      "Epoch: 2101, Loss: 4.251\n",
      "Epoch: 2201, Loss: 3.358\n",
      "Epoch: 2301, Loss: 4.748\n",
      "Epoch: 2401, Loss: 3.570\n",
      "Epoch: 2501, Loss: 3.477\n",
      "Epoch: 2601, Loss: 3.311\n",
      "Epoch: 2701, Loss: 3.643\n",
      "Epoch: 2801, Loss: 4.686\n",
      "Epoch: 2901, Loss: 3.505\n",
      "Epoch: 3001, Loss: 3.921\n",
      "Epoch: 3101, Loss: 3.406\n",
      "Epoch: 3201, Loss: 3.568\n",
      "Epoch: 3301, Loss: 3.531\n",
      "Epoch: 3401, Loss: 3.695\n",
      "Epoch: 3501, Loss: 3.307\n",
      "Epoch: 3601, Loss: 3.459\n",
      "Epoch: 3701, Loss: 3.409\n",
      "Epoch: 3801, Loss: 4.096\n",
      "Epoch: 3901, Loss: 3.738\n",
      "Epoch: 4001, Loss: 3.328\n",
      "Epoch: 4101, Loss: 3.716\n",
      "Epoch: 4201, Loss: 4.096\n",
      "Epoch: 4301, Loss: 3.598\n",
      "Epoch: 4401, Loss: 3.052\n",
      "Epoch: 4501, Loss: 3.750\n",
      "Epoch: 4601, Loss: 3.328\n",
      "Epoch: 4701, Loss: 3.597\n",
      "Epoch: 4801, Loss: 3.764\n",
      "Epoch: 4901, Loss: 3.570\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check out the new network architecture and dataset!\n",
    "Notice that the weights and biases are\n",
    "generated randomly.\n",
    "No need to change anything, but feel free to tweak\n",
    "to test your network, play around with the epochs, batch size, etc!\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "#from miniflow import *\n",
    "\n",
    "# Load data\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "\n",
    "# Normalize data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural network\n",
    "X, y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 5000\n",
    "# Total number of examples\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "print(\"Total number of examples = {}\".format(m))\n",
    "\n",
    "# Step 4\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # Step 1\n",
    "        # Randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "\n",
    "        # Reset value of X and y Inputs\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "\n",
    "        # Step 2\n",
    "        _ = None\n",
    "        forward_and_backward(_, graph) # set output node not important.\n",
    "\n",
    "        # Step 3\n",
    "        rate = 1e-2\n",
    "    \n",
    "        sgd_update(trainables, rate)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "    \n",
    "    if i % 100 == 0: \n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1dcfeef0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.95526956],\n",
       "       [ 4.44502603],\n",
       "       [-6.94135244],\n",
       "       [ 7.44602655],\n",
       "       [ 6.97476219],\n",
       "       [ 9.96077996],\n",
       "       [ 5.41560844],\n",
       "       [ 9.18734159],\n",
       "       [ 6.82344011],\n",
       "       [ 4.8044769 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/heany/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, activation='sigmoid', input_dim=13))\n",
    "model.add(Dense(units=30, activation='sigmoid', input_dim=64))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/heany/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "506/506 [==============================] - 0s 209us/step - loss: 147.1745 - mean_squared_error: 147.1745\n",
      "Epoch 2/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 83.8460 - mean_squared_error: 83.8460\n",
      "Epoch 3/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 82.3513 - mean_squared_error: 82.3513\n",
      "Epoch 4/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 83.4382 - mean_squared_error: 83.4382\n",
      "Epoch 5/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 82.3099 - mean_squared_error: 82.3099\n",
      "Epoch 6/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 82.7377 - mean_squared_error: 82.7377\n",
      "Epoch 7/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 81.6347 - mean_squared_error: 81.6347\n",
      "Epoch 8/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 80.5546 - mean_squared_error: 80.5546\n",
      "Epoch 9/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8653 - mean_squared_error: 84.8653\n",
      "Epoch 10/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.9908 - mean_squared_error: 85.9908\n",
      "Epoch 11/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5342 - mean_squared_error: 85.5342\n",
      "Epoch 12/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 86.9710 - mean_squared_error: 86.9710\n",
      "Epoch 13/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.1315 - mean_squared_error: 85.1315\n",
      "Epoch 14/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4370 - mean_squared_error: 85.4370\n",
      "Epoch 15/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.7386 - mean_squared_error: 84.7386\n",
      "Epoch 16/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7426 - mean_squared_error: 84.7426\n",
      "Epoch 17/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8994 - mean_squared_error: 84.8994\n",
      "Epoch 18/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3139 - mean_squared_error: 85.3139\n",
      "Epoch 19/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4805 - mean_squared_error: 85.4805\n",
      "Epoch 20/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2257 - mean_squared_error: 85.2257\n",
      "Epoch 21/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.9333 - mean_squared_error: 85.9333\n",
      "Epoch 22/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4698 - mean_squared_error: 85.4698\n",
      "Epoch 23/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1141 - mean_squared_error: 85.1141\n",
      "Epoch 24/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.9868 - mean_squared_error: 85.9868\n",
      "Epoch 25/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8822 - mean_squared_error: 84.8822\n",
      "Epoch 26/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2478 - mean_squared_error: 85.2478\n",
      "Epoch 27/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9882 - mean_squared_error: 84.9882\n",
      "Epoch 28/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.6730 - mean_squared_error: 84.6730\n",
      "Epoch 29/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0045 - mean_squared_error: 85.0045\n",
      "Epoch 30/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 86.1356 - mean_squared_error: 86.1356\n",
      "Epoch 31/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.9074 - mean_squared_error: 84.9074\n",
      "Epoch 32/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3074 - mean_squared_error: 85.3074\n",
      "Epoch 33/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2449 - mean_squared_error: 85.2449\n",
      "Epoch 34/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1198 - mean_squared_error: 85.1198\n",
      "Epoch 35/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7348 - mean_squared_error: 85.7348\n",
      "Epoch 36/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.5643 - mean_squared_error: 84.5643\n",
      "Epoch 37/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.6461 - mean_squared_error: 85.6461\n",
      "Epoch 38/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1934 - mean_squared_error: 85.1934\n",
      "Epoch 39/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.1505 - mean_squared_error: 85.1505\n",
      "Epoch 40/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.3104 - mean_squared_error: 85.3104\n",
      "Epoch 41/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1529 - mean_squared_error: 85.1529\n",
      "Epoch 42/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.0864 - mean_squared_error: 85.0864\n",
      "Epoch 43/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.2659 - mean_squared_error: 85.2659\n",
      "Epoch 44/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.5704 - mean_squared_error: 85.5704\n",
      "Epoch 45/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.1882 - mean_squared_error: 85.1882\n",
      "Epoch 46/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.2391 - mean_squared_error: 85.2391\n",
      "Epoch 47/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.3284 - mean_squared_error: 85.3284\n",
      "Epoch 48/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.7411 - mean_squared_error: 85.7411\n",
      "Epoch 49/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.7647 - mean_squared_error: 84.7647\n",
      "Epoch 50/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.4873 - mean_squared_error: 85.4873\n",
      "Epoch 51/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.8991 - mean_squared_error: 85.8991\n",
      "Epoch 52/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.5084 - mean_squared_error: 84.5084\n",
      "Epoch 53/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.0421 - mean_squared_error: 85.0421\n",
      "Epoch 54/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.8153 - mean_squared_error: 84.8153\n",
      "Epoch 55/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.4196 - mean_squared_error: 85.4196\n",
      "Epoch 56/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.3140 - mean_squared_error: 85.3140\n",
      "Epoch 57/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7248 - mean_squared_error: 85.7248\n",
      "Epoch 58/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 84.7221 - mean_squared_error: 84.7221\n",
      "Epoch 59/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.6372 - mean_squared_error: 84.6372\n",
      "Epoch 60/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.9952 - mean_squared_error: 84.9952\n",
      "Epoch 61/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 84.2622 - mean_squared_error: 84.2622\n",
      "Epoch 62/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.1611 - mean_squared_error: 85.1611\n",
      "Epoch 63/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.0475 - mean_squared_error: 85.0475\n",
      "Epoch 64/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.5213 - mean_squared_error: 85.5213\n",
      "Epoch 65/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0247 - mean_squared_error: 85.0247\n",
      "Epoch 66/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.7928 - mean_squared_error: 84.7928\n",
      "Epoch 67/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.4350 - mean_squared_error: 85.4350\n",
      "Epoch 68/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 84.6450 - mean_squared_error: 84.6450\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 21us/step - loss: 86.4844 - mean_squared_error: 86.4844\n",
      "Epoch 70/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.3675 - mean_squared_error: 85.3675\n",
      "Epoch 71/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.3642 - mean_squared_error: 85.3642\n",
      "Epoch 72/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2408 - mean_squared_error: 85.2408\n",
      "Epoch 73/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.3192 - mean_squared_error: 85.3192\n",
      "Epoch 74/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.2569 - mean_squared_error: 84.2569\n",
      "Epoch 75/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.3601 - mean_squared_error: 84.3601\n",
      "Epoch 76/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5991 - mean_squared_error: 85.5991\n",
      "Epoch 77/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 86.3414 - mean_squared_error: 86.3414\n",
      "Epoch 78/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1046 - mean_squared_error: 85.1046\n",
      "Epoch 79/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1141 - mean_squared_error: 85.1141\n",
      "Epoch 80/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.5198 - mean_squared_error: 85.5198\n",
      "Epoch 81/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.9675 - mean_squared_error: 84.9675\n",
      "Epoch 82/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1781 - mean_squared_error: 85.1781\n",
      "Epoch 83/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.9397 - mean_squared_error: 85.9397\n",
      "Epoch 84/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.4869 - mean_squared_error: 85.4869\n",
      "Epoch 85/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.8881 - mean_squared_error: 84.8881\n",
      "Epoch 86/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.0420 - mean_squared_error: 85.0420\n",
      "Epoch 87/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.5753 - mean_squared_error: 85.5753\n",
      "Epoch 88/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.1199 - mean_squared_error: 85.1199\n",
      "Epoch 89/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.7324 - mean_squared_error: 85.7324\n",
      "Epoch 90/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 84.6746 - mean_squared_error: 84.6746\n",
      "Epoch 91/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.2035 - mean_squared_error: 85.2035\n",
      "Epoch 92/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.5771 - mean_squared_error: 85.5771\n",
      "Epoch 93/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.8871 - mean_squared_error: 84.8871\n",
      "Epoch 94/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.6106 - mean_squared_error: 85.6106\n",
      "Epoch 95/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3848 - mean_squared_error: 85.3848\n",
      "Epoch 96/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4642 - mean_squared_error: 85.4642\n",
      "Epoch 97/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.7676 - mean_squared_error: 84.7676\n",
      "Epoch 98/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.8410 - mean_squared_error: 84.8410\n",
      "Epoch 99/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.4161 - mean_squared_error: 84.4161\n",
      "Epoch 100/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.0226 - mean_squared_error: 85.0226\n",
      "Epoch 101/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1607 - mean_squared_error: 85.1607\n",
      "Epoch 102/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.4574 - mean_squared_error: 85.4574\n",
      "Epoch 103/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.0885 - mean_squared_error: 85.0885\n",
      "Epoch 104/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 86.9410 - mean_squared_error: 86.9410\n",
      "Epoch 105/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 84.9423 - mean_squared_error: 84.9423\n",
      "Epoch 106/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3175 - mean_squared_error: 85.3175\n",
      "Epoch 107/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0465 - mean_squared_error: 85.0465\n",
      "Epoch 108/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.1986 - mean_squared_error: 84.1986\n",
      "Epoch 109/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.2215 - mean_squared_error: 85.2215\n",
      "Epoch 110/1000\n",
      "506/506 [==============================] - 0s 17us/step - loss: 85.4941 - mean_squared_error: 85.4941\n",
      "Epoch 111/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.4293 - mean_squared_error: 84.4293\n",
      "Epoch 112/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.5623 - mean_squared_error: 84.5623\n",
      "Epoch 113/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 83.4973 - mean_squared_error: 83.4973\n",
      "Epoch 114/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 83.7648 - mean_squared_error: 83.7648\n",
      "Epoch 115/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.0324 - mean_squared_error: 85.0324\n",
      "Epoch 116/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0289 - mean_squared_error: 85.0289\n",
      "Epoch 117/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.7534 - mean_squared_error: 85.7534\n",
      "Epoch 118/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.3623 - mean_squared_error: 84.3623\n",
      "Epoch 119/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.6618 - mean_squared_error: 85.6618\n",
      "Epoch 120/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1205 - mean_squared_error: 85.1205\n",
      "Epoch 121/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.4457 - mean_squared_error: 84.4457\n",
      "Epoch 122/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.7600 - mean_squared_error: 85.7600\n",
      "Epoch 123/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 84.9178 - mean_squared_error: 84.9178\n",
      "Epoch 124/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.7868 - mean_squared_error: 85.7868\n",
      "Epoch 125/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.6642 - mean_squared_error: 84.6642\n",
      "Epoch 126/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.3196 - mean_squared_error: 84.3196\n",
      "Epoch 127/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8816 - mean_squared_error: 84.8816\n",
      "Epoch 128/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1853 - mean_squared_error: 85.1853\n",
      "Epoch 129/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.2459 - mean_squared_error: 85.2459\n",
      "Epoch 130/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3424 - mean_squared_error: 85.3424\n",
      "Epoch 131/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.8128 - mean_squared_error: 84.8128\n",
      "Epoch 132/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2408 - mean_squared_error: 85.2408\n",
      "Epoch 133/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3217 - mean_squared_error: 85.3217\n",
      "Epoch 134/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9801 - mean_squared_error: 84.9801\n",
      "Epoch 135/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7099 - mean_squared_error: 84.7099\n",
      "Epoch 136/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.2924 - mean_squared_error: 84.2924\n",
      "Epoch 137/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.6944 - mean_squared_error: 85.6944\n",
      "Epoch 138/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.9358 - mean_squared_error: 84.9358\n",
      "Epoch 139/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 20us/step - loss: 85.7324 - mean_squared_error: 85.7324\n",
      "Epoch 140/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.6550 - mean_squared_error: 85.6550\n",
      "Epoch 141/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3312 - mean_squared_error: 85.3312\n",
      "Epoch 142/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0253 - mean_squared_error: 85.0253\n",
      "Epoch 143/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1306 - mean_squared_error: 85.1306\n",
      "Epoch 144/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1500 - mean_squared_error: 85.1500\n",
      "Epoch 145/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.8030 - mean_squared_error: 84.8030\n",
      "Epoch 146/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.4510 - mean_squared_error: 85.4510\n",
      "Epoch 147/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1203 - mean_squared_error: 85.1203\n",
      "Epoch 148/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 86.0879 - mean_squared_error: 86.0879\n",
      "Epoch 149/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 84.7279 - mean_squared_error: 84.7279\n",
      "Epoch 150/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.1949 - mean_squared_error: 85.1949\n",
      "Epoch 151/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.9124 - mean_squared_error: 84.9124\n",
      "Epoch 152/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1803 - mean_squared_error: 85.1803\n",
      "Epoch 153/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.2278 - mean_squared_error: 85.2278\n",
      "Epoch 154/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.1174 - mean_squared_error: 85.1174\n",
      "Epoch 155/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1689 - mean_squared_error: 85.1689\n",
      "Epoch 156/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.4071 - mean_squared_error: 85.4071\n",
      "Epoch 157/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 86.3535 - mean_squared_error: 86.3535\n",
      "Epoch 158/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.3738 - mean_squared_error: 85.3738\n",
      "Epoch 159/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.2235 - mean_squared_error: 85.2235\n",
      "Epoch 160/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 84.9969 - mean_squared_error: 84.9969\n",
      "Epoch 161/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.9259 - mean_squared_error: 85.9259\n",
      "Epoch 162/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 84.9334 - mean_squared_error: 84.9334\n",
      "Epoch 163/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0712 - mean_squared_error: 85.0712\n",
      "Epoch 164/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.0932 - mean_squared_error: 85.0932\n",
      "Epoch 165/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.5023 - mean_squared_error: 85.5023\n",
      "Epoch 166/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.7534 - mean_squared_error: 85.7534\n",
      "Epoch 167/1000\n",
      "506/506 [==============================] - 0s 17us/step - loss: 85.1947 - mean_squared_error: 85.1947\n",
      "Epoch 168/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.0424 - mean_squared_error: 85.0424\n",
      "Epoch 169/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.4827 - mean_squared_error: 84.4827\n",
      "Epoch 170/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.5825 - mean_squared_error: 85.5825\n",
      "Epoch 171/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.9075 - mean_squared_error: 84.9075\n",
      "Epoch 172/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.8519 - mean_squared_error: 84.8519\n",
      "Epoch 173/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8698 - mean_squared_error: 84.8698\n",
      "Epoch 174/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.8975 - mean_squared_error: 84.8975\n",
      "Epoch 175/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5575 - mean_squared_error: 85.5575\n",
      "Epoch 176/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3847 - mean_squared_error: 85.3847\n",
      "Epoch 177/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9681 - mean_squared_error: 84.9681\n",
      "Epoch 178/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.3271 - mean_squared_error: 84.3271\n",
      "Epoch 179/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4095 - mean_squared_error: 85.4095\n",
      "Epoch 180/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.0719 - mean_squared_error: 85.0719\n",
      "Epoch 181/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9685 - mean_squared_error: 84.9685\n",
      "Epoch 182/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3418 - mean_squared_error: 85.3418\n",
      "Epoch 183/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.6235 - mean_squared_error: 85.6235\n",
      "Epoch 184/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.0332 - mean_squared_error: 85.0332\n",
      "Epoch 185/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9818 - mean_squared_error: 84.9818\n",
      "Epoch 186/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8637 - mean_squared_error: 84.8637\n",
      "Epoch 187/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3120 - mean_squared_error: 85.3120\n",
      "Epoch 188/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7758 - mean_squared_error: 84.7758\n",
      "Epoch 189/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2864 - mean_squared_error: 85.2864\n",
      "Epoch 190/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.6499 - mean_squared_error: 84.6499\n",
      "Epoch 191/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0560 - mean_squared_error: 85.0560\n",
      "Epoch 192/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.5625 - mean_squared_error: 85.5625\n",
      "Epoch 193/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.7645 - mean_squared_error: 84.7645\n",
      "Epoch 194/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.6219 - mean_squared_error: 84.6219\n",
      "Epoch 195/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1844 - mean_squared_error: 85.1844\n",
      "Epoch 196/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.8955 - mean_squared_error: 85.8955\n",
      "Epoch 197/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8224 - mean_squared_error: 84.8224\n",
      "Epoch 198/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1335 - mean_squared_error: 85.1335\n",
      "Epoch 199/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.6328 - mean_squared_error: 84.6328\n",
      "Epoch 200/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1234 - mean_squared_error: 85.1234\n",
      "Epoch 201/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.9768 - mean_squared_error: 84.9768\n",
      "Epoch 202/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.5663 - mean_squared_error: 84.5663\n",
      "Epoch 203/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7877 - mean_squared_error: 84.7877\n",
      "Epoch 204/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.6988 - mean_squared_error: 84.6988\n",
      "Epoch 205/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 83.8506 - mean_squared_error: 83.8506\n",
      "Epoch 206/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3203 - mean_squared_error: 85.3203\n",
      "Epoch 207/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0941 - mean_squared_error: 85.0941\n",
      "Epoch 208/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.4034 - mean_squared_error: 84.4034\n",
      "Epoch 209/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 20us/step - loss: 84.2799 - mean_squared_error: 84.2799\n",
      "Epoch 210/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.0050 - mean_squared_error: 84.0050\n",
      "Epoch 211/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7665 - mean_squared_error: 84.7665\n",
      "Epoch 212/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0873 - mean_squared_error: 85.0873\n",
      "Epoch 213/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.2550 - mean_squared_error: 84.2550\n",
      "Epoch 214/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.5711 - mean_squared_error: 84.5711\n",
      "Epoch 215/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3679 - mean_squared_error: 85.3679\n",
      "Epoch 216/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3252 - mean_squared_error: 85.3252\n",
      "Epoch 217/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.7791 - mean_squared_error: 85.7791\n",
      "Epoch 218/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9796 - mean_squared_error: 84.9796\n",
      "Epoch 219/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.9459 - mean_squared_error: 84.9459\n",
      "Epoch 220/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.6358 - mean_squared_error: 85.6358\n",
      "Epoch 221/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5167 - mean_squared_error: 85.5167\n",
      "Epoch 222/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.0928 - mean_squared_error: 84.0928\n",
      "Epoch 223/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0474 - mean_squared_error: 85.0474\n",
      "Epoch 224/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0458 - mean_squared_error: 85.0458\n",
      "Epoch 225/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.8228 - mean_squared_error: 85.8228\n",
      "Epoch 226/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.6174 - mean_squared_error: 85.6174\n",
      "Epoch 227/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3319 - mean_squared_error: 85.3319\n",
      "Epoch 228/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3703 - mean_squared_error: 85.3703\n",
      "Epoch 229/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4065 - mean_squared_error: 85.4065\n",
      "Epoch 230/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9117 - mean_squared_error: 84.9117\n",
      "Epoch 231/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5095 - mean_squared_error: 85.5095\n",
      "Epoch 232/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8966 - mean_squared_error: 84.8966\n",
      "Epoch 233/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 86.2543 - mean_squared_error: 86.2543\n",
      "Epoch 234/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9873 - mean_squared_error: 84.9873\n",
      "Epoch 235/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4346 - mean_squared_error: 85.4346\n",
      "Epoch 236/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7078 - mean_squared_error: 84.7078\n",
      "Epoch 237/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3970 - mean_squared_error: 85.3970\n",
      "Epoch 238/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.9277 - mean_squared_error: 85.9277\n",
      "Epoch 239/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4422 - mean_squared_error: 85.4422\n",
      "Epoch 240/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0686 - mean_squared_error: 85.0686\n",
      "Epoch 241/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8741 - mean_squared_error: 84.8741\n",
      "Epoch 242/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2662 - mean_squared_error: 85.2662\n",
      "Epoch 243/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9656 - mean_squared_error: 84.9656\n",
      "Epoch 244/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2887 - mean_squared_error: 85.2887\n",
      "Epoch 245/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.5608 - mean_squared_error: 85.5608\n",
      "Epoch 246/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0081 - mean_squared_error: 85.0081\n",
      "Epoch 247/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9772 - mean_squared_error: 84.9772\n",
      "Epoch 248/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1743 - mean_squared_error: 85.1743\n",
      "Epoch 249/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.2420 - mean_squared_error: 84.2420\n",
      "Epoch 250/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0407 - mean_squared_error: 85.0407\n",
      "Epoch 251/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.7325 - mean_squared_error: 84.7325\n",
      "Epoch 252/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.7895 - mean_squared_error: 84.7895\n",
      "Epoch 253/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9813 - mean_squared_error: 84.9813\n",
      "Epoch 254/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2849 - mean_squared_error: 85.2849\n",
      "Epoch 255/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.6214 - mean_squared_error: 85.6214\n",
      "Epoch 256/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0968 - mean_squared_error: 85.0968\n",
      "Epoch 257/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.9468 - mean_squared_error: 84.9468\n",
      "Epoch 258/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9404 - mean_squared_error: 84.9404\n",
      "Epoch 259/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1667 - mean_squared_error: 85.1667\n",
      "Epoch 260/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 86.0240 - mean_squared_error: 86.0240\n",
      "Epoch 261/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.7351 - mean_squared_error: 84.7351\n",
      "Epoch 262/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2126 - mean_squared_error: 85.2126\n",
      "Epoch 263/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.3354 - mean_squared_error: 84.3354\n",
      "Epoch 264/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3961 - mean_squared_error: 85.3961\n",
      "Epoch 265/1000\n",
      "506/506 [==============================] - 0s 31us/step - loss: 85.2429 - mean_squared_error: 85.2429\n",
      "Epoch 266/1000\n",
      "506/506 [==============================] - 0s 26us/step - loss: 84.9685 - mean_squared_error: 84.9685\n",
      "Epoch 267/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.6111 - mean_squared_error: 84.6111\n",
      "Epoch 268/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.6229 - mean_squared_error: 85.6229\n",
      "Epoch 269/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3808 - mean_squared_error: 85.3808\n",
      "Epoch 270/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.8995 - mean_squared_error: 84.8995\n",
      "Epoch 271/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8780 - mean_squared_error: 84.8780\n",
      "Epoch 272/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1952 - mean_squared_error: 85.1952\n",
      "Epoch 273/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8535 - mean_squared_error: 84.8535\n",
      "Epoch 274/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.7644 - mean_squared_error: 84.7644\n",
      "Epoch 275/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7002 - mean_squared_error: 84.7002\n",
      "Epoch 276/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.2552 - mean_squared_error: 85.2552\n",
      "Epoch 277/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.8484 - mean_squared_error: 84.8484\n",
      "Epoch 278/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1661 - mean_squared_error: 85.1661\n",
      "Epoch 279/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 22us/step - loss: 84.8915 - mean_squared_error: 84.8915\n",
      "Epoch 280/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9732 - mean_squared_error: 84.9732\n",
      "Epoch 281/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.3143 - mean_squared_error: 85.3143\n",
      "Epoch 282/1000\n",
      "506/506 [==============================] - 0s 26us/step - loss: 85.2911 - mean_squared_error: 85.2911\n",
      "Epoch 283/1000\n",
      "506/506 [==============================] - 0s 27us/step - loss: 84.9074 - mean_squared_error: 84.9074\n",
      "Epoch 284/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.5449 - mean_squared_error: 85.5449\n",
      "Epoch 285/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.6192 - mean_squared_error: 84.6192\n",
      "Epoch 286/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9883 - mean_squared_error: 84.9883\n",
      "Epoch 287/1000\n",
      "506/506 [==============================] - 0s 27us/step - loss: 85.2527 - mean_squared_error: 85.2527\n",
      "Epoch 288/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.0207 - mean_squared_error: 85.0207\n",
      "Epoch 289/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.7327 - mean_squared_error: 84.7327\n",
      "Epoch 290/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.6281 - mean_squared_error: 85.6281\n",
      "Epoch 291/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.2837 - mean_squared_error: 85.2837\n",
      "Epoch 292/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.2026 - mean_squared_error: 85.2026\n",
      "Epoch 293/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1531 - mean_squared_error: 85.1531\n",
      "Epoch 294/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1443 - mean_squared_error: 85.1443\n",
      "Epoch 295/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9227 - mean_squared_error: 84.9227\n",
      "Epoch 296/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.2861 - mean_squared_error: 85.2861\n",
      "Epoch 297/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1754 - mean_squared_error: 85.1754\n",
      "Epoch 298/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3929 - mean_squared_error: 85.3929\n",
      "Epoch 299/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.7951 - mean_squared_error: 85.7951\n",
      "Epoch 300/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4127 - mean_squared_error: 85.4127\n",
      "Epoch 301/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.8432 - mean_squared_error: 85.8432\n",
      "Epoch 302/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.9963 - mean_squared_error: 84.9963\n",
      "Epoch 303/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.0041 - mean_squared_error: 85.0041\n",
      "Epoch 304/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.3640 - mean_squared_error: 85.3640\n",
      "Epoch 305/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.9255 - mean_squared_error: 84.9255\n",
      "Epoch 306/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.4099 - mean_squared_error: 85.4099\n",
      "Epoch 307/1000\n",
      "506/506 [==============================] - 0s 27us/step - loss: 85.2828 - mean_squared_error: 85.2828\n",
      "Epoch 308/1000\n",
      "506/506 [==============================] - 0s 26us/step - loss: 85.8986 - mean_squared_error: 85.8986\n",
      "Epoch 309/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.0044 - mean_squared_error: 85.0044\n",
      "Epoch 310/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.8450 - mean_squared_error: 84.8450\n",
      "Epoch 311/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.5146 - mean_squared_error: 84.5146\n",
      "Epoch 312/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.4904 - mean_squared_error: 84.4904\n",
      "Epoch 313/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9865 - mean_squared_error: 84.9865\n",
      "Epoch 314/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.2704 - mean_squared_error: 84.2704\n",
      "Epoch 315/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.3456 - mean_squared_error: 85.3456\n",
      "Epoch 316/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.6991 - mean_squared_error: 85.6991\n",
      "Epoch 317/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 86.3198 - mean_squared_error: 86.3198\n",
      "Epoch 318/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.4083 - mean_squared_error: 84.4083\n",
      "Epoch 319/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.7377 - mean_squared_error: 85.7377\n",
      "Epoch 320/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.7920 - mean_squared_error: 85.7920\n",
      "Epoch 321/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 86.0687 - mean_squared_error: 86.0687\n",
      "Epoch 322/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2712 - mean_squared_error: 85.2712\n",
      "Epoch 323/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.5634 - mean_squared_error: 84.5634\n",
      "Epoch 324/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2940 - mean_squared_error: 85.2940\n",
      "Epoch 325/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7414 - mean_squared_error: 84.7414\n",
      "Epoch 326/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2309 - mean_squared_error: 85.2309\n",
      "Epoch 327/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.7510 - mean_squared_error: 85.7510\n",
      "Epoch 328/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2634 - mean_squared_error: 85.2634\n",
      "Epoch 329/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8667 - mean_squared_error: 84.8667\n",
      "Epoch 330/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8824 - mean_squared_error: 84.8824\n",
      "Epoch 331/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1067 - mean_squared_error: 85.1067\n",
      "Epoch 332/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5237 - mean_squared_error: 85.5237\n",
      "Epoch 333/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2451 - mean_squared_error: 85.2451\n",
      "Epoch 334/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3763 - mean_squared_error: 85.3763\n",
      "Epoch 335/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.0018 - mean_squared_error: 84.0018\n",
      "Epoch 336/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.6499 - mean_squared_error: 85.6499\n",
      "Epoch 337/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.6419 - mean_squared_error: 85.6419\n",
      "Epoch 338/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.6492 - mean_squared_error: 85.6492\n",
      "Epoch 339/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3810 - mean_squared_error: 85.3810\n",
      "Epoch 340/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.5876 - mean_squared_error: 85.5876\n",
      "Epoch 341/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1574 - mean_squared_error: 85.1574\n",
      "Epoch 342/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4805 - mean_squared_error: 85.4805\n",
      "Epoch 343/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.9767 - mean_squared_error: 84.9767\n",
      "Epoch 344/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8458 - mean_squared_error: 84.8458\n",
      "Epoch 345/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 86.1849 - mean_squared_error: 86.1849\n",
      "Epoch 346/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0491 - mean_squared_error: 85.0491\n",
      "Epoch 347/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1579 - mean_squared_error: 85.1579\n",
      "Epoch 348/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2555 - mean_squared_error: 85.2555\n",
      "Epoch 349/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 22us/step - loss: 85.3929 - mean_squared_error: 85.3929\n",
      "Epoch 350/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1987 - mean_squared_error: 85.1987\n",
      "Epoch 351/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.4121 - mean_squared_error: 85.4121\n",
      "Epoch 352/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3581 - mean_squared_error: 85.3581\n",
      "Epoch 353/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7305 - mean_squared_error: 84.7305\n",
      "Epoch 354/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.5387 - mean_squared_error: 84.5387\n",
      "Epoch 355/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7378 - mean_squared_error: 85.7378\n",
      "Epoch 356/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9091 - mean_squared_error: 84.9091\n",
      "Epoch 357/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.4906 - mean_squared_error: 85.4906\n",
      "Epoch 358/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.6220 - mean_squared_error: 84.6220\n",
      "Epoch 359/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0723 - mean_squared_error: 85.0723\n",
      "Epoch 360/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0197 - mean_squared_error: 85.0197\n",
      "Epoch 361/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.6445 - mean_squared_error: 84.6445\n",
      "Epoch 362/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.2858 - mean_squared_error: 85.2858\n",
      "Epoch 363/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9606 - mean_squared_error: 84.9606\n",
      "Epoch 364/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2189 - mean_squared_error: 85.2189\n",
      "Epoch 365/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.7802 - mean_squared_error: 84.7802\n",
      "Epoch 366/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4975 - mean_squared_error: 85.4975\n",
      "Epoch 367/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1532 - mean_squared_error: 85.1532\n",
      "Epoch 368/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 84.7449 - mean_squared_error: 84.7449\n",
      "Epoch 369/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4119 - mean_squared_error: 85.4119\n",
      "Epoch 370/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.6776 - mean_squared_error: 84.6776\n",
      "Epoch 371/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.8394 - mean_squared_error: 85.8394\n",
      "Epoch 372/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9775 - mean_squared_error: 84.9775\n",
      "Epoch 373/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.5456 - mean_squared_error: 85.5456\n",
      "Epoch 374/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4703 - mean_squared_error: 85.4703\n",
      "Epoch 375/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.7450 - mean_squared_error: 85.7450\n",
      "Epoch 376/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.2975 - mean_squared_error: 84.2975\n",
      "Epoch 377/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.6767 - mean_squared_error: 84.6767\n",
      "Epoch 378/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9698 - mean_squared_error: 84.9698\n",
      "Epoch 379/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4209 - mean_squared_error: 85.4209\n",
      "Epoch 380/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.6262 - mean_squared_error: 84.6262\n",
      "Epoch 381/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4507 - mean_squared_error: 85.4507\n",
      "Epoch 382/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.8717 - mean_squared_error: 85.8717\n",
      "Epoch 383/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7059 - mean_squared_error: 85.7059\n",
      "Epoch 384/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.5360 - mean_squared_error: 85.5360\n",
      "Epoch 385/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.8321 - mean_squared_error: 84.8321\n",
      "Epoch 386/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 86.6161 - mean_squared_error: 86.6161\n",
      "Epoch 387/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 86.7792 - mean_squared_error: 86.7792\n",
      "Epoch 388/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0489 - mean_squared_error: 85.0489\n",
      "Epoch 389/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8878 - mean_squared_error: 84.8878\n",
      "Epoch 390/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3097 - mean_squared_error: 85.3097\n",
      "Epoch 391/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.5130 - mean_squared_error: 84.5130\n",
      "Epoch 392/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5647 - mean_squared_error: 85.5647\n",
      "Epoch 393/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4188 - mean_squared_error: 85.4188\n",
      "Epoch 394/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2429 - mean_squared_error: 85.2429\n",
      "Epoch 395/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9060 - mean_squared_error: 84.9060\n",
      "Epoch 396/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8368 - mean_squared_error: 84.8368\n",
      "Epoch 397/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.5273 - mean_squared_error: 85.5273\n",
      "Epoch 398/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.5142 - mean_squared_error: 85.5142\n",
      "Epoch 399/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7613 - mean_squared_error: 85.7613\n",
      "Epoch 400/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.6867 - mean_squared_error: 84.6867\n",
      "Epoch 401/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 83.7892 - mean_squared_error: 83.7892\n",
      "Epoch 402/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7681 - mean_squared_error: 85.7681\n",
      "Epoch 403/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0473 - mean_squared_error: 85.0473\n",
      "Epoch 404/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8292 - mean_squared_error: 84.8292\n",
      "Epoch 405/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.3046 - mean_squared_error: 85.3046\n",
      "Epoch 406/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4226 - mean_squared_error: 85.4226\n",
      "Epoch 407/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.8635 - mean_squared_error: 85.8635\n",
      "Epoch 408/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3136 - mean_squared_error: 85.3136\n",
      "Epoch 409/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0928 - mean_squared_error: 85.0928\n",
      "Epoch 410/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.4016 - mean_squared_error: 85.4016\n",
      "Epoch 411/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.1584 - mean_squared_error: 85.1584\n",
      "Epoch 412/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.8251 - mean_squared_error: 85.8251\n",
      "Epoch 413/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9784 - mean_squared_error: 84.9784\n",
      "Epoch 414/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7081 - mean_squared_error: 84.7081\n",
      "Epoch 415/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4204 - mean_squared_error: 85.4204\n",
      "Epoch 416/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4772 - mean_squared_error: 85.4772\n",
      "Epoch 417/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4763 - mean_squared_error: 85.4763\n",
      "Epoch 418/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.6762 - mean_squared_error: 84.6762\n",
      "Epoch 419/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 22us/step - loss: 85.6699 - mean_squared_error: 85.6699\n",
      "Epoch 420/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1183 - mean_squared_error: 85.1183\n",
      "Epoch 421/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.8627 - mean_squared_error: 85.8627\n",
      "Epoch 422/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9235 - mean_squared_error: 84.9235\n",
      "Epoch 423/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 86.0253 - mean_squared_error: 86.0253\n",
      "Epoch 424/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3134 - mean_squared_error: 85.3134\n",
      "Epoch 425/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5915 - mean_squared_error: 85.5915\n",
      "Epoch 426/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5480 - mean_squared_error: 85.5480\n",
      "Epoch 427/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2514 - mean_squared_error: 85.2514\n",
      "Epoch 428/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.6025 - mean_squared_error: 84.6025\n",
      "Epoch 429/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.8000 - mean_squared_error: 85.8000\n",
      "Epoch 430/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2356 - mean_squared_error: 85.2356\n",
      "Epoch 431/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0946 - mean_squared_error: 85.0946\n",
      "Epoch 432/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.7729 - mean_squared_error: 84.7729\n",
      "Epoch 433/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1011 - mean_squared_error: 85.1011\n",
      "Epoch 434/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3079 - mean_squared_error: 85.3079\n",
      "Epoch 435/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1670 - mean_squared_error: 85.1670\n",
      "Epoch 436/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5908 - mean_squared_error: 85.5908\n",
      "Epoch 437/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7088 - mean_squared_error: 84.7088\n",
      "Epoch 438/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1641 - mean_squared_error: 85.1641\n",
      "Epoch 439/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.6457 - mean_squared_error: 84.6457\n",
      "Epoch 440/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2749 - mean_squared_error: 85.2749\n",
      "Epoch 441/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8000 - mean_squared_error: 84.8000\n",
      "Epoch 442/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2025 - mean_squared_error: 85.2025\n",
      "Epoch 443/1000\n",
      "506/506 [==============================] - 0s 28us/step - loss: 84.2494 - mean_squared_error: 84.2494\n",
      "Epoch 444/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.2383 - mean_squared_error: 85.2383\n",
      "Epoch 445/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1173 - mean_squared_error: 85.1173\n",
      "Epoch 446/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.9755 - mean_squared_error: 84.9755\n",
      "Epoch 447/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.4231 - mean_squared_error: 85.4231\n",
      "Epoch 448/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.2964 - mean_squared_error: 85.2964\n",
      "Epoch 449/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.4766 - mean_squared_error: 85.4766\n",
      "Epoch 450/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1411 - mean_squared_error: 85.1411\n",
      "Epoch 451/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4854 - mean_squared_error: 85.4854\n",
      "Epoch 452/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0162 - mean_squared_error: 85.0162\n",
      "Epoch 453/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0759 - mean_squared_error: 85.0759\n",
      "Epoch 454/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0615 - mean_squared_error: 85.0615\n",
      "Epoch 455/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9764 - mean_squared_error: 84.9764\n",
      "Epoch 456/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3769 - mean_squared_error: 85.3769\n",
      "Epoch 457/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1571 - mean_squared_error: 85.1571\n",
      "Epoch 458/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3688 - mean_squared_error: 85.3688\n",
      "Epoch 459/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2597 - mean_squared_error: 85.2597\n",
      "Epoch 460/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1853 - mean_squared_error: 85.1853\n",
      "Epoch 461/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0843 - mean_squared_error: 85.0843\n",
      "Epoch 462/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8421 - mean_squared_error: 84.8421\n",
      "Epoch 463/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1247 - mean_squared_error: 85.1247\n",
      "Epoch 464/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8690 - mean_squared_error: 84.8690\n",
      "Epoch 465/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3645 - mean_squared_error: 85.3645\n",
      "Epoch 466/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.8296 - mean_squared_error: 85.8296\n",
      "Epoch 467/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0460 - mean_squared_error: 85.0460\n",
      "Epoch 468/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.6029 - mean_squared_error: 85.6029\n",
      "Epoch 469/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7302 - mean_squared_error: 84.7302\n",
      "Epoch 470/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.8112 - mean_squared_error: 84.8112\n",
      "Epoch 471/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9037 - mean_squared_error: 84.9037\n",
      "Epoch 472/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8705 - mean_squared_error: 84.8705\n",
      "Epoch 473/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7163 - mean_squared_error: 84.7163\n",
      "Epoch 474/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9006 - mean_squared_error: 84.9006\n",
      "Epoch 475/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8042 - mean_squared_error: 84.8042\n",
      "Epoch 476/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.4560 - mean_squared_error: 84.4560\n",
      "Epoch 477/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.6245 - mean_squared_error: 85.6245\n",
      "Epoch 478/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9824 - mean_squared_error: 84.9824\n",
      "Epoch 479/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8567 - mean_squared_error: 84.8567\n",
      "Epoch 480/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.8222 - mean_squared_error: 85.8222\n",
      "Epoch 481/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1896 - mean_squared_error: 85.1896\n",
      "Epoch 482/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4583 - mean_squared_error: 85.4583\n",
      "Epoch 483/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7819 - mean_squared_error: 84.7819\n",
      "Epoch 484/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.5555 - mean_squared_error: 84.5555\n",
      "Epoch 485/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7285 - mean_squared_error: 85.7285\n",
      "Epoch 486/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7096 - mean_squared_error: 85.7096\n",
      "Epoch 487/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8685 - mean_squared_error: 84.8685\n",
      "Epoch 488/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1865 - mean_squared_error: 85.1865\n",
      "Epoch 489/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 22us/step - loss: 85.0244 - mean_squared_error: 85.0244\n",
      "Epoch 490/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.1600 - mean_squared_error: 84.1600\n",
      "Epoch 491/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 83.8124 - mean_squared_error: 83.8124\n",
      "Epoch 492/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8476 - mean_squared_error: 84.8476\n",
      "Epoch 493/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.3761 - mean_squared_error: 85.3761\n",
      "Epoch 494/1000\n",
      "506/506 [==============================] - 0s 27us/step - loss: 85.0780 - mean_squared_error: 85.0780\n",
      "Epoch 495/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.9395 - mean_squared_error: 85.9395\n",
      "Epoch 496/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4548 - mean_squared_error: 85.4548\n",
      "Epoch 497/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.2576 - mean_squared_error: 85.2576\n",
      "Epoch 498/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.1653 - mean_squared_error: 85.1653\n",
      "Epoch 499/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4400 - mean_squared_error: 85.4400\n",
      "Epoch 500/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3088 - mean_squared_error: 85.3088\n",
      "Epoch 501/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3584 - mean_squared_error: 85.3584\n",
      "Epoch 502/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.5714 - mean_squared_error: 85.5714\n",
      "Epoch 503/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5831 - mean_squared_error: 85.5831\n",
      "Epoch 504/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.5713 - mean_squared_error: 85.5713\n",
      "Epoch 505/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2367 - mean_squared_error: 85.2367\n",
      "Epoch 506/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.4261 - mean_squared_error: 84.4261\n",
      "Epoch 507/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.5649 - mean_squared_error: 84.5649\n",
      "Epoch 508/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9614 - mean_squared_error: 84.9614\n",
      "Epoch 509/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8927 - mean_squared_error: 84.8927\n",
      "Epoch 510/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5340 - mean_squared_error: 85.5340\n",
      "Epoch 511/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1976 - mean_squared_error: 85.1976\n",
      "Epoch 512/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5766 - mean_squared_error: 85.5766\n",
      "Epoch 513/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.4423 - mean_squared_error: 84.4423\n",
      "Epoch 514/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9764 - mean_squared_error: 84.9764\n",
      "Epoch 515/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3786 - mean_squared_error: 85.3786\n",
      "Epoch 516/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0356 - mean_squared_error: 85.0356\n",
      "Epoch 517/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.1663 - mean_squared_error: 84.1663\n",
      "Epoch 518/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.1485 - mean_squared_error: 85.1485\n",
      "Epoch 519/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1973 - mean_squared_error: 85.1973\n",
      "Epoch 520/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.3202 - mean_squared_error: 85.3202\n",
      "Epoch 521/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.7346 - mean_squared_error: 84.7346\n",
      "Epoch 522/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.2425 - mean_squared_error: 84.2425\n",
      "Epoch 523/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2505 - mean_squared_error: 85.2505\n",
      "Epoch 524/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.0546 - mean_squared_error: 84.0546\n",
      "Epoch 525/1000\n",
      "506/506 [==============================] - 0s 26us/step - loss: 86.2235 - mean_squared_error: 86.2235\n",
      "Epoch 526/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.0683 - mean_squared_error: 85.0683\n",
      "Epoch 527/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.6989 - mean_squared_error: 84.6989\n",
      "Epoch 528/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.6920 - mean_squared_error: 85.6920\n",
      "Epoch 529/1000\n",
      "506/506 [==============================] - 0s 26us/step - loss: 85.3526 - mean_squared_error: 85.3526\n",
      "Epoch 530/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.5771 - mean_squared_error: 84.5771\n",
      "Epoch 531/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.9408 - mean_squared_error: 85.9408\n",
      "Epoch 532/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.4024 - mean_squared_error: 84.4024\n",
      "Epoch 533/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7986 - mean_squared_error: 84.7986\n",
      "Epoch 534/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.5226 - mean_squared_error: 84.5226\n",
      "Epoch 535/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9979 - mean_squared_error: 84.9979\n",
      "Epoch 536/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1363 - mean_squared_error: 85.1363\n",
      "Epoch 537/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1924 - mean_squared_error: 85.1924\n",
      "Epoch 538/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.5367 - mean_squared_error: 85.5367\n",
      "Epoch 539/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.5360 - mean_squared_error: 85.5360\n",
      "Epoch 540/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.3815 - mean_squared_error: 85.3815\n",
      "Epoch 541/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1623 - mean_squared_error: 85.1623\n",
      "Epoch 542/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9100 - mean_squared_error: 84.9100\n",
      "Epoch 543/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8754 - mean_squared_error: 84.8754\n",
      "Epoch 544/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9283 - mean_squared_error: 84.9283\n",
      "Epoch 545/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3589 - mean_squared_error: 85.3589\n",
      "Epoch 546/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9575 - mean_squared_error: 84.9575\n",
      "Epoch 547/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4977 - mean_squared_error: 85.4977\n",
      "Epoch 548/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7180 - mean_squared_error: 84.7180\n",
      "Epoch 549/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8402 - mean_squared_error: 84.8402\n",
      "Epoch 550/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8763 - mean_squared_error: 84.8763\n",
      "Epoch 551/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7786 - mean_squared_error: 84.7786\n",
      "Epoch 552/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.7366 - mean_squared_error: 84.7366\n",
      "Epoch 553/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.5181 - mean_squared_error: 84.5181\n",
      "Epoch 554/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9193 - mean_squared_error: 84.9193\n",
      "Epoch 555/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.8107 - mean_squared_error: 84.8107\n",
      "Epoch 556/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0097 - mean_squared_error: 85.0097\n",
      "Epoch 557/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0048 - mean_squared_error: 85.0048\n",
      "Epoch 558/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.6879 - mean_squared_error: 84.6879\n",
      "Epoch 559/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 23us/step - loss: 84.6292 - mean_squared_error: 84.6292\n",
      "Epoch 560/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9420 - mean_squared_error: 84.9420\n",
      "Epoch 561/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1481 - mean_squared_error: 85.1481\n",
      "Epoch 562/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2555 - mean_squared_error: 85.2555\n",
      "Epoch 563/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1855 - mean_squared_error: 85.1855\n",
      "Epoch 564/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2522 - mean_squared_error: 85.2522\n",
      "Epoch 565/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0224 - mean_squared_error: 85.0224\n",
      "Epoch 566/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2454 - mean_squared_error: 85.2454\n",
      "Epoch 567/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.5565 - mean_squared_error: 84.5565\n",
      "Epoch 568/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8585 - mean_squared_error: 84.8585\n",
      "Epoch 569/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3505 - mean_squared_error: 85.3505\n",
      "Epoch 570/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5357 - mean_squared_error: 85.5357\n",
      "Epoch 571/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.5102 - mean_squared_error: 84.5102\n",
      "Epoch 572/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9954 - mean_squared_error: 84.9954\n",
      "Epoch 573/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.6229 - mean_squared_error: 84.6229\n",
      "Epoch 574/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.6607 - mean_squared_error: 85.6607\n",
      "Epoch 575/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.6083 - mean_squared_error: 85.6083\n",
      "Epoch 576/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0470 - mean_squared_error: 85.0470\n",
      "Epoch 577/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4619 - mean_squared_error: 85.4619\n",
      "Epoch 578/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.5816 - mean_squared_error: 85.5816\n",
      "Epoch 579/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3626 - mean_squared_error: 85.3626\n",
      "Epoch 580/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0857 - mean_squared_error: 85.0857\n",
      "Epoch 581/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8905 - mean_squared_error: 84.8905\n",
      "Epoch 582/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1849 - mean_squared_error: 85.1849\n",
      "Epoch 583/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8774 - mean_squared_error: 84.8774\n",
      "Epoch 584/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2965 - mean_squared_error: 85.2965\n",
      "Epoch 585/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1278 - mean_squared_error: 85.1278\n",
      "Epoch 586/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2082 - mean_squared_error: 85.2082\n",
      "Epoch 587/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.9043 - mean_squared_error: 85.9043\n",
      "Epoch 588/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9662 - mean_squared_error: 84.9662\n",
      "Epoch 589/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8393 - mean_squared_error: 84.8393\n",
      "Epoch 590/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.4975 - mean_squared_error: 84.4975\n",
      "Epoch 591/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.7289 - mean_squared_error: 85.7289\n",
      "Epoch 592/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.0483 - mean_squared_error: 85.0483\n",
      "Epoch 593/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1614 - mean_squared_error: 85.1614\n",
      "Epoch 594/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8507 - mean_squared_error: 84.8507\n",
      "Epoch 595/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.5554 - mean_squared_error: 85.5554\n",
      "Epoch 596/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8845 - mean_squared_error: 84.8845\n",
      "Epoch 597/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8547 - mean_squared_error: 84.8547\n",
      "Epoch 598/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3835 - mean_squared_error: 85.3835\n",
      "Epoch 599/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7013 - mean_squared_error: 84.7013\n",
      "Epoch 600/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0293 - mean_squared_error: 85.0293\n",
      "Epoch 601/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8137 - mean_squared_error: 84.8137\n",
      "Epoch 602/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.0259 - mean_squared_error: 85.0259\n",
      "Epoch 603/1000\n",
      "506/506 [==============================] - 0s 28us/step - loss: 85.3403 - mean_squared_error: 85.3403\n",
      "Epoch 604/1000\n",
      "506/506 [==============================] - 0s 29us/step - loss: 85.7643 - mean_squared_error: 85.7643\n",
      "Epoch 605/1000\n",
      "506/506 [==============================] - 0s 26us/step - loss: 85.1080 - mean_squared_error: 85.1080\n",
      "Epoch 606/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.6722 - mean_squared_error: 84.6722\n",
      "Epoch 607/1000\n",
      "506/506 [==============================] - 0s 26us/step - loss: 84.8725 - mean_squared_error: 84.8725\n",
      "Epoch 608/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.3757 - mean_squared_error: 85.3757\n",
      "Epoch 609/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2911 - mean_squared_error: 85.2911\n",
      "Epoch 610/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.7603 - mean_squared_error: 84.7603\n",
      "Epoch 611/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.7776 - mean_squared_error: 84.7776\n",
      "Epoch 612/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0442 - mean_squared_error: 85.0442\n",
      "Epoch 613/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.4882 - mean_squared_error: 84.4882\n",
      "Epoch 614/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2427 - mean_squared_error: 85.2427\n",
      "Epoch 615/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1258 - mean_squared_error: 85.1258\n",
      "Epoch 616/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8078 - mean_squared_error: 84.8078\n",
      "Epoch 617/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.8794 - mean_squared_error: 84.8794\n",
      "Epoch 618/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1549 - mean_squared_error: 85.1549\n",
      "Epoch 619/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1992 - mean_squared_error: 85.1992\n",
      "Epoch 620/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0922 - mean_squared_error: 85.0922\n",
      "Epoch 621/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4107 - mean_squared_error: 85.4107\n",
      "Epoch 622/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.6891 - mean_squared_error: 84.6891\n",
      "Epoch 623/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.5958 - mean_squared_error: 85.5958\n",
      "Epoch 624/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1033 - mean_squared_error: 85.1033\n",
      "Epoch 625/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.5243 - mean_squared_error: 85.5243\n",
      "Epoch 626/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7997 - mean_squared_error: 84.7997\n",
      "Epoch 627/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4671 - mean_squared_error: 85.4671\n",
      "Epoch 628/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7133 - mean_squared_error: 85.7133\n",
      "Epoch 629/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 21us/step - loss: 85.1676 - mean_squared_error: 85.1676\n",
      "Epoch 630/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.9196 - mean_squared_error: 84.9196\n",
      "Epoch 631/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7496 - mean_squared_error: 84.7496\n",
      "Epoch 632/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.5072 - mean_squared_error: 84.5072\n",
      "Epoch 633/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.2966 - mean_squared_error: 85.2966\n",
      "Epoch 634/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9604 - mean_squared_error: 84.9604\n",
      "Epoch 635/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9330 - mean_squared_error: 84.9330\n",
      "Epoch 636/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 86.6711 - mean_squared_error: 86.6711\n",
      "Epoch 637/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9931 - mean_squared_error: 84.9931\n",
      "Epoch 638/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0357 - mean_squared_error: 85.0357\n",
      "Epoch 639/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.7703 - mean_squared_error: 85.7703\n",
      "Epoch 640/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.6667 - mean_squared_error: 85.6667\n",
      "Epoch 641/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.8726 - mean_squared_error: 85.8726\n",
      "Epoch 642/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2190 - mean_squared_error: 85.2190\n",
      "Epoch 643/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1146 - mean_squared_error: 85.1146\n",
      "Epoch 644/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2475 - mean_squared_error: 85.2475\n",
      "Epoch 645/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1362 - mean_squared_error: 85.1362\n",
      "Epoch 646/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5507 - mean_squared_error: 85.5507\n",
      "Epoch 647/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.9176 - mean_squared_error: 84.9176\n",
      "Epoch 648/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1547 - mean_squared_error: 85.1547\n",
      "Epoch 649/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7283 - mean_squared_error: 84.7283\n",
      "Epoch 650/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.6637 - mean_squared_error: 84.6637\n",
      "Epoch 651/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.5972 - mean_squared_error: 85.5972\n",
      "Epoch 652/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2192 - mean_squared_error: 85.2192\n",
      "Epoch 653/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.9428 - mean_squared_error: 85.9428\n",
      "Epoch 654/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2691 - mean_squared_error: 85.2691\n",
      "Epoch 655/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0374 - mean_squared_error: 85.0374\n",
      "Epoch 656/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0144 - mean_squared_error: 85.0144\n",
      "Epoch 657/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7157 - mean_squared_error: 84.7157\n",
      "Epoch 658/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1871 - mean_squared_error: 85.1871\n",
      "Epoch 659/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3745 - mean_squared_error: 85.3745\n",
      "Epoch 660/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4606 - mean_squared_error: 85.4606\n",
      "Epoch 661/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0449 - mean_squared_error: 85.0449\n",
      "Epoch 662/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.5804 - mean_squared_error: 85.5804\n",
      "Epoch 663/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9415 - mean_squared_error: 84.9415\n",
      "Epoch 664/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2035 - mean_squared_error: 85.2035\n",
      "Epoch 665/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4181 - mean_squared_error: 85.4181\n",
      "Epoch 666/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9150 - mean_squared_error: 84.9150\n",
      "Epoch 667/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7370 - mean_squared_error: 84.7370\n",
      "Epoch 668/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0311 - mean_squared_error: 85.0311\n",
      "Epoch 669/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9614 - mean_squared_error: 84.9614\n",
      "Epoch 670/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3029 - mean_squared_error: 85.3029\n",
      "Epoch 671/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.8253 - mean_squared_error: 85.8253\n",
      "Epoch 672/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3214 - mean_squared_error: 85.3214\n",
      "Epoch 673/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2718 - mean_squared_error: 85.2718\n",
      "Epoch 674/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2503 - mean_squared_error: 85.2503\n",
      "Epoch 675/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.8361 - mean_squared_error: 85.8361\n",
      "Epoch 676/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2231 - mean_squared_error: 85.2231\n",
      "Epoch 677/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.8230 - mean_squared_error: 84.8230\n",
      "Epoch 678/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8009 - mean_squared_error: 84.8009\n",
      "Epoch 679/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.5225 - mean_squared_error: 85.5225\n",
      "Epoch 680/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.8621 - mean_squared_error: 85.8621\n",
      "Epoch 681/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1568 - mean_squared_error: 85.1568\n",
      "Epoch 682/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0462 - mean_squared_error: 85.0462\n",
      "Epoch 683/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1043 - mean_squared_error: 85.1043\n",
      "Epoch 684/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0417 - mean_squared_error: 85.0417\n",
      "Epoch 685/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2214 - mean_squared_error: 85.2214\n",
      "Epoch 686/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.7550 - mean_squared_error: 85.7550\n",
      "Epoch 687/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2742 - mean_squared_error: 85.2742\n",
      "Epoch 688/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2504 - mean_squared_error: 85.2504\n",
      "Epoch 689/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3694 - mean_squared_error: 85.3694\n",
      "Epoch 690/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8992 - mean_squared_error: 84.8992\n",
      "Epoch 691/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2446 - mean_squared_error: 85.2446\n",
      "Epoch 692/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.6641 - mean_squared_error: 84.6641\n",
      "Epoch 693/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.6663 - mean_squared_error: 84.6663\n",
      "Epoch 694/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2248 - mean_squared_error: 85.2248\n",
      "Epoch 695/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9990 - mean_squared_error: 84.9990\n",
      "Epoch 696/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7341 - mean_squared_error: 84.7341\n",
      "Epoch 697/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.2010 - mean_squared_error: 85.2010\n",
      "Epoch 698/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9652 - mean_squared_error: 84.9652\n",
      "Epoch 699/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 21us/step - loss: 84.3124 - mean_squared_error: 84.3124\n",
      "Epoch 700/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0179 - mean_squared_error: 85.0179\n",
      "Epoch 701/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.9210 - mean_squared_error: 84.9210\n",
      "Epoch 702/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0249 - mean_squared_error: 85.0249\n",
      "Epoch 703/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.1671 - mean_squared_error: 85.1671\n",
      "Epoch 704/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8474 - mean_squared_error: 84.8474\n",
      "Epoch 705/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.5964 - mean_squared_error: 84.5964\n",
      "Epoch 706/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.8358 - mean_squared_error: 84.8358\n",
      "Epoch 707/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8132 - mean_squared_error: 84.8132\n",
      "Epoch 708/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0568 - mean_squared_error: 85.0568\n",
      "Epoch 709/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2206 - mean_squared_error: 85.2206\n",
      "Epoch 710/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9827 - mean_squared_error: 84.9827\n",
      "Epoch 711/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7506 - mean_squared_error: 85.7506\n",
      "Epoch 712/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2211 - mean_squared_error: 85.2211\n",
      "Epoch 713/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0878 - mean_squared_error: 85.0878\n",
      "Epoch 714/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.2407 - mean_squared_error: 85.2407\n",
      "Epoch 715/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1094 - mean_squared_error: 85.1094\n",
      "Epoch 716/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1276 - mean_squared_error: 85.1276\n",
      "Epoch 717/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0808 - mean_squared_error: 85.0808\n",
      "Epoch 718/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9081 - mean_squared_error: 84.9081\n",
      "Epoch 719/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9585 - mean_squared_error: 84.9585\n",
      "Epoch 720/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3175 - mean_squared_error: 85.3175\n",
      "Epoch 721/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3864 - mean_squared_error: 85.3864\n",
      "Epoch 722/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8435 - mean_squared_error: 84.8435\n",
      "Epoch 723/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.9834 - mean_squared_error: 84.9834\n",
      "Epoch 724/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.4501 - mean_squared_error: 84.4501\n",
      "Epoch 725/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9393 - mean_squared_error: 84.9393\n",
      "Epoch 726/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8034 - mean_squared_error: 84.8034\n",
      "Epoch 727/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9367 - mean_squared_error: 84.9367\n",
      "Epoch 728/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1662 - mean_squared_error: 85.1662\n",
      "Epoch 729/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.6673 - mean_squared_error: 85.6673\n",
      "Epoch 730/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3754 - mean_squared_error: 85.3754\n",
      "Epoch 731/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.1549 - mean_squared_error: 85.1549\n",
      "Epoch 732/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7927 - mean_squared_error: 84.7927\n",
      "Epoch 733/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3155 - mean_squared_error: 85.3155\n",
      "Epoch 734/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 86.6312 - mean_squared_error: 86.6312\n",
      "Epoch 735/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8295 - mean_squared_error: 84.8295\n",
      "Epoch 736/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2207 - mean_squared_error: 85.2207\n",
      "Epoch 737/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.9055 - mean_squared_error: 84.9055\n",
      "Epoch 738/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8875 - mean_squared_error: 84.8875\n",
      "Epoch 739/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3828 - mean_squared_error: 85.3828\n",
      "Epoch 740/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.5125 - mean_squared_error: 85.5125\n",
      "Epoch 741/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.0964 - mean_squared_error: 85.0964\n",
      "Epoch 742/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2074 - mean_squared_error: 85.2074\n",
      "Epoch 743/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4648 - mean_squared_error: 85.4648\n",
      "Epoch 744/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1657 - mean_squared_error: 85.1657\n",
      "Epoch 745/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.6074 - mean_squared_error: 85.6074\n",
      "Epoch 746/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.0104 - mean_squared_error: 85.0104\n",
      "Epoch 747/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8192 - mean_squared_error: 84.8192\n",
      "Epoch 748/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9279 - mean_squared_error: 84.9279\n",
      "Epoch 749/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.0408 - mean_squared_error: 85.0408\n",
      "Epoch 750/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.8499 - mean_squared_error: 85.8499\n",
      "Epoch 751/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.1899 - mean_squared_error: 85.1899\n",
      "Epoch 752/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9894 - mean_squared_error: 84.9894\n",
      "Epoch 753/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.8433 - mean_squared_error: 84.8433\n",
      "Epoch 754/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.5989 - mean_squared_error: 84.5989\n",
      "Epoch 755/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2471 - mean_squared_error: 85.2471\n",
      "Epoch 756/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.7027 - mean_squared_error: 84.7027\n",
      "Epoch 757/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1628 - mean_squared_error: 85.1628\n",
      "Epoch 758/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7613 - mean_squared_error: 85.7613\n",
      "Epoch 759/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9138 - mean_squared_error: 84.9138\n",
      "Epoch 760/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2351 - mean_squared_error: 85.2351\n",
      "Epoch 761/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1025 - mean_squared_error: 85.1025\n",
      "Epoch 762/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 86.2565 - mean_squared_error: 86.2565\n",
      "Epoch 763/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.5708 - mean_squared_error: 85.5708\n",
      "Epoch 764/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0477 - mean_squared_error: 85.0477\n",
      "Epoch 765/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9203 - mean_squared_error: 84.9203\n",
      "Epoch 766/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4472 - mean_squared_error: 85.4472\n",
      "Epoch 767/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.1819 - mean_squared_error: 84.1819\n",
      "Epoch 768/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3729 - mean_squared_error: 85.3729\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 23us/step - loss: 85.4653 - mean_squared_error: 85.4653\n",
      "Epoch 770/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.4735 - mean_squared_error: 85.4735\n",
      "Epoch 771/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1197 - mean_squared_error: 85.1197\n",
      "Epoch 772/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1598 - mean_squared_error: 85.1598\n",
      "Epoch 773/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1042 - mean_squared_error: 85.1042\n",
      "Epoch 774/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2324 - mean_squared_error: 85.2324\n",
      "Epoch 775/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.9174 - mean_squared_error: 84.9174\n",
      "Epoch 776/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7439 - mean_squared_error: 84.7439\n",
      "Epoch 777/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.1256 - mean_squared_error: 85.1256\n",
      "Epoch 778/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.9402 - mean_squared_error: 84.9402\n",
      "Epoch 779/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.2592 - mean_squared_error: 85.2592\n",
      "Epoch 780/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8031 - mean_squared_error: 84.8031\n",
      "Epoch 781/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 86.2773 - mean_squared_error: 86.2773\n",
      "Epoch 782/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1012 - mean_squared_error: 85.1012\n",
      "Epoch 783/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0404 - mean_squared_error: 85.0404\n",
      "Epoch 784/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2859 - mean_squared_error: 85.2859\n",
      "Epoch 785/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9729 - mean_squared_error: 84.9729\n",
      "Epoch 786/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.8509 - mean_squared_error: 85.8509\n",
      "Epoch 787/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7926 - mean_squared_error: 84.7926\n",
      "Epoch 788/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.7813 - mean_squared_error: 84.7813\n",
      "Epoch 789/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.6202 - mean_squared_error: 85.6202\n",
      "Epoch 790/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.4174 - mean_squared_error: 84.4174\n",
      "Epoch 791/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9594 - mean_squared_error: 84.9594\n",
      "Epoch 792/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.5574 - mean_squared_error: 84.5574\n",
      "Epoch 793/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.4185 - mean_squared_error: 85.4185\n",
      "Epoch 794/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9843 - mean_squared_error: 84.9843\n",
      "Epoch 795/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.9129 - mean_squared_error: 84.9129\n",
      "Epoch 796/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.3464 - mean_squared_error: 85.3464\n",
      "Epoch 797/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8684 - mean_squared_error: 84.8684\n",
      "Epoch 798/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.3435 - mean_squared_error: 84.3435\n",
      "Epoch 799/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.3057 - mean_squared_error: 84.3057\n",
      "Epoch 800/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.6295 - mean_squared_error: 84.6295\n",
      "Epoch 801/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1668 - mean_squared_error: 85.1668\n",
      "Epoch 802/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4610 - mean_squared_error: 85.4610\n",
      "Epoch 803/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4458 - mean_squared_error: 85.4458\n",
      "Epoch 804/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.0221 - mean_squared_error: 85.0221\n",
      "Epoch 805/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8446 - mean_squared_error: 84.8446\n",
      "Epoch 806/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1347 - mean_squared_error: 85.1347\n",
      "Epoch 807/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0192 - mean_squared_error: 85.0192\n",
      "Epoch 808/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2818 - mean_squared_error: 85.2818\n",
      "Epoch 809/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8885 - mean_squared_error: 84.8885\n",
      "Epoch 810/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1519 - mean_squared_error: 85.1519\n",
      "Epoch 811/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.3631 - mean_squared_error: 84.3631\n",
      "Epoch 812/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2379 - mean_squared_error: 85.2379\n",
      "Epoch 813/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.7507 - mean_squared_error: 85.7507\n",
      "Epoch 814/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9461 - mean_squared_error: 84.9461\n",
      "Epoch 815/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7247 - mean_squared_error: 84.7247\n",
      "Epoch 816/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.0943 - mean_squared_error: 85.0943\n",
      "Epoch 817/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3277 - mean_squared_error: 85.3277\n",
      "Epoch 818/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4106 - mean_squared_error: 85.4106\n",
      "Epoch 819/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.5182 - mean_squared_error: 85.5182\n",
      "Epoch 820/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.9106 - mean_squared_error: 85.9106\n",
      "Epoch 821/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1001 - mean_squared_error: 85.1001\n",
      "Epoch 822/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4254 - mean_squared_error: 85.4254\n",
      "Epoch 823/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9405 - mean_squared_error: 84.9405\n",
      "Epoch 824/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1316 - mean_squared_error: 85.1316\n",
      "Epoch 825/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4631 - mean_squared_error: 85.4631\n",
      "Epoch 826/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.5153 - mean_squared_error: 85.5153\n",
      "Epoch 827/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9967 - mean_squared_error: 84.9967\n",
      "Epoch 828/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1529 - mean_squared_error: 85.1529\n",
      "Epoch 829/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.0156 - mean_squared_error: 85.0156\n",
      "Epoch 830/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.0639 - mean_squared_error: 85.0639\n",
      "Epoch 831/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1928 - mean_squared_error: 85.1928\n",
      "Epoch 832/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 83.9168 - mean_squared_error: 83.9168\n",
      "Epoch 833/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2799 - mean_squared_error: 85.2799\n",
      "Epoch 834/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0625 - mean_squared_error: 85.0625\n",
      "Epoch 835/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1597 - mean_squared_error: 85.1597\n",
      "Epoch 836/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1836 - mean_squared_error: 85.1836\n",
      "Epoch 837/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9405 - mean_squared_error: 84.9405\n",
      "Epoch 838/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2051 - mean_squared_error: 85.2051\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 22us/step - loss: 84.7366 - mean_squared_error: 84.7366\n",
      "Epoch 840/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2066 - mean_squared_error: 85.2066\n",
      "Epoch 841/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0962 - mean_squared_error: 85.0962\n",
      "Epoch 842/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4997 - mean_squared_error: 85.4997\n",
      "Epoch 843/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.8246 - mean_squared_error: 84.8246\n",
      "Epoch 844/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8309 - mean_squared_error: 84.8309\n",
      "Epoch 845/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.5879 - mean_squared_error: 85.5879\n",
      "Epoch 846/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3153 - mean_squared_error: 85.3153\n",
      "Epoch 847/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9848 - mean_squared_error: 84.9848\n",
      "Epoch 848/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7811 - mean_squared_error: 84.7811\n",
      "Epoch 849/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0885 - mean_squared_error: 85.0885\n",
      "Epoch 850/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7749 - mean_squared_error: 84.7749\n",
      "Epoch 851/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.4773 - mean_squared_error: 85.4773\n",
      "Epoch 852/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3667 - mean_squared_error: 85.3667\n",
      "Epoch 853/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3373 - mean_squared_error: 85.3373\n",
      "Epoch 854/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.3605 - mean_squared_error: 85.3605\n",
      "Epoch 855/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1438 - mean_squared_error: 85.1438\n",
      "Epoch 856/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7718 - mean_squared_error: 84.7718\n",
      "Epoch 857/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.6709 - mean_squared_error: 84.6709\n",
      "Epoch 858/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9102 - mean_squared_error: 84.9102\n",
      "Epoch 859/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7067 - mean_squared_error: 84.7067\n",
      "Epoch 860/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4400 - mean_squared_error: 85.4400\n",
      "Epoch 861/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7821 - mean_squared_error: 84.7821\n",
      "Epoch 862/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9592 - mean_squared_error: 84.9592\n",
      "Epoch 863/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8998 - mean_squared_error: 84.8998\n",
      "Epoch 864/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2560 - mean_squared_error: 85.2560\n",
      "Epoch 865/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3969 - mean_squared_error: 85.3969\n",
      "Epoch 866/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0477 - mean_squared_error: 85.0477\n",
      "Epoch 867/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4192 - mean_squared_error: 85.4192\n",
      "Epoch 868/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4541 - mean_squared_error: 85.4541\n",
      "Epoch 869/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.6995 - mean_squared_error: 84.6995\n",
      "Epoch 870/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.1257 - mean_squared_error: 84.1257\n",
      "Epoch 871/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.5007 - mean_squared_error: 85.5007\n",
      "Epoch 872/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9344 - mean_squared_error: 84.9344\n",
      "Epoch 873/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.6089 - mean_squared_error: 85.6089\n",
      "Epoch 874/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.1634 - mean_squared_error: 85.1634\n",
      "Epoch 875/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8637 - mean_squared_error: 84.8637\n",
      "Epoch 876/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.7954 - mean_squared_error: 84.7954\n",
      "Epoch 877/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.5114 - mean_squared_error: 84.5114\n",
      "Epoch 878/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3510 - mean_squared_error: 85.3510\n",
      "Epoch 879/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7713 - mean_squared_error: 84.7713\n",
      "Epoch 880/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.6777 - mean_squared_error: 85.6777\n",
      "Epoch 881/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.4303 - mean_squared_error: 84.4303\n",
      "Epoch 882/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.3792 - mean_squared_error: 85.3792\n",
      "Epoch 883/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2875 - mean_squared_error: 85.2875\n",
      "Epoch 884/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7867 - mean_squared_error: 84.7867\n",
      "Epoch 885/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9957 - mean_squared_error: 84.9957\n",
      "Epoch 886/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0906 - mean_squared_error: 85.0906\n",
      "Epoch 887/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4426 - mean_squared_error: 85.4426\n",
      "Epoch 888/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0154 - mean_squared_error: 85.0154\n",
      "Epoch 889/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0373 - mean_squared_error: 85.0373\n",
      "Epoch 890/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2242 - mean_squared_error: 85.2242\n",
      "Epoch 891/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1074 - mean_squared_error: 85.1074\n",
      "Epoch 892/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 86.0138 - mean_squared_error: 86.0138\n",
      "Epoch 893/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.9172 - mean_squared_error: 84.9172\n",
      "Epoch 894/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 83.8148 - mean_squared_error: 83.8148\n",
      "Epoch 895/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.2244 - mean_squared_error: 85.2244\n",
      "Epoch 896/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.2328 - mean_squared_error: 85.2328\n",
      "Epoch 897/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.5555 - mean_squared_error: 84.5555\n",
      "Epoch 898/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.2363 - mean_squared_error: 85.2363\n",
      "Epoch 899/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9981 - mean_squared_error: 84.9981\n",
      "Epoch 900/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0632 - mean_squared_error: 85.0632\n",
      "Epoch 901/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0352 - mean_squared_error: 85.0352\n",
      "Epoch 902/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0916 - mean_squared_error: 85.0916\n",
      "Epoch 903/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8031 - mean_squared_error: 84.8031\n",
      "Epoch 904/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9594 - mean_squared_error: 84.9594\n",
      "Epoch 905/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.5396 - mean_squared_error: 85.5396\n",
      "Epoch 906/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2795 - mean_squared_error: 85.2795\n",
      "Epoch 907/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8783 - mean_squared_error: 84.8783\n",
      "Epoch 908/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1086 - mean_squared_error: 85.1086\n",
      "Epoch 909/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 24us/step - loss: 85.1707 - mean_squared_error: 85.1707\n",
      "Epoch 910/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.9515 - mean_squared_error: 84.9515\n",
      "Epoch 911/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2104 - mean_squared_error: 85.2104\n",
      "Epoch 912/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.7239 - mean_squared_error: 84.7239\n",
      "Epoch 913/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2924 - mean_squared_error: 85.2924\n",
      "Epoch 914/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3808 - mean_squared_error: 85.3808\n",
      "Epoch 915/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.5931 - mean_squared_error: 84.5931\n",
      "Epoch 916/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4205 - mean_squared_error: 85.4205\n",
      "Epoch 917/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.6173 - mean_squared_error: 84.6173\n",
      "Epoch 918/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.1121 - mean_squared_error: 85.1121\n",
      "Epoch 919/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.5372 - mean_squared_error: 85.5372\n",
      "Epoch 920/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.1801 - mean_squared_error: 85.1801\n",
      "Epoch 921/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.8644 - mean_squared_error: 84.8644\n",
      "Epoch 922/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.7676 - mean_squared_error: 84.7676\n",
      "Epoch 923/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3003 - mean_squared_error: 85.3003\n",
      "Epoch 924/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.4990 - mean_squared_error: 85.4990\n",
      "Epoch 925/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9721 - mean_squared_error: 84.9721\n",
      "Epoch 926/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.1855 - mean_squared_error: 85.1855\n",
      "Epoch 927/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 84.6722 - mean_squared_error: 84.6722\n",
      "Epoch 928/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0509 - mean_squared_error: 85.0509\n",
      "Epoch 929/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.8674 - mean_squared_error: 85.8674\n",
      "Epoch 930/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.1077 - mean_squared_error: 85.1077\n",
      "Epoch 931/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.2244 - mean_squared_error: 85.2244\n",
      "Epoch 932/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.3881 - mean_squared_error: 85.3881\n",
      "Epoch 933/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1838 - mean_squared_error: 85.1838\n",
      "Epoch 934/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.8288 - mean_squared_error: 85.8288\n",
      "Epoch 935/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1323 - mean_squared_error: 85.1323\n",
      "Epoch 936/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0638 - mean_squared_error: 85.0638\n",
      "Epoch 937/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.5133 - mean_squared_error: 84.5133\n",
      "Epoch 938/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.7671 - mean_squared_error: 85.7671\n",
      "Epoch 939/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4749 - mean_squared_error: 85.4749\n",
      "Epoch 940/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.0156 - mean_squared_error: 85.0156\n",
      "Epoch 941/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 86.0636 - mean_squared_error: 86.0636\n",
      "Epoch 942/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.7149 - mean_squared_error: 84.7149\n",
      "Epoch 943/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.0799 - mean_squared_error: 85.0799\n",
      "Epoch 944/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.1753 - mean_squared_error: 85.1753\n",
      "Epoch 945/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.5656 - mean_squared_error: 85.5656\n",
      "Epoch 946/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.9015 - mean_squared_error: 84.9015\n",
      "Epoch 947/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.1129 - mean_squared_error: 85.1129\n",
      "Epoch 948/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.2120 - mean_squared_error: 85.2120\n",
      "Epoch 949/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.2656 - mean_squared_error: 85.2656\n",
      "Epoch 950/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.4754 - mean_squared_error: 85.4754\n",
      "Epoch 951/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9842 - mean_squared_error: 84.9842\n",
      "Epoch 952/1000\n",
      "506/506 [==============================] - 0s 26us/step - loss: 84.6107 - mean_squared_error: 84.6107\n",
      "Epoch 953/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.0155 - mean_squared_error: 85.0155\n",
      "Epoch 954/1000\n",
      "506/506 [==============================] - 0s 27us/step - loss: 84.8700 - mean_squared_error: 84.8700\n",
      "Epoch 955/1000\n",
      "506/506 [==============================] - 0s 28us/step - loss: 84.9046 - mean_squared_error: 84.9046\n",
      "Epoch 956/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.2165 - mean_squared_error: 85.2165\n",
      "Epoch 957/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.1636 - mean_squared_error: 85.1636\n",
      "Epoch 958/1000\n",
      "506/506 [==============================] - 0s 27us/step - loss: 85.1140 - mean_squared_error: 85.1140\n",
      "Epoch 959/1000\n",
      "506/506 [==============================] - 0s 27us/step - loss: 84.9446 - mean_squared_error: 84.9446\n",
      "Epoch 960/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.0560 - mean_squared_error: 85.0560\n",
      "Epoch 961/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.9909 - mean_squared_error: 84.9909\n",
      "Epoch 962/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 84.4845 - mean_squared_error: 84.4845\n",
      "Epoch 963/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.3379 - mean_squared_error: 85.3379\n",
      "Epoch 964/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0030 - mean_squared_error: 85.0030\n",
      "Epoch 965/1000\n",
      "506/506 [==============================] - 0s 24us/step - loss: 85.0880 - mean_squared_error: 85.0880\n",
      "Epoch 966/1000\n",
      "506/506 [==============================] - 0s 27us/step - loss: 84.7367 - mean_squared_error: 84.7367\n",
      "Epoch 967/1000\n",
      "506/506 [==============================] - 0s 28us/step - loss: 85.3947 - mean_squared_error: 85.3947\n",
      "Epoch 968/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 84.7320 - mean_squared_error: 84.7320\n",
      "Epoch 969/1000\n",
      "506/506 [==============================] - ETA: 0s - loss: 113.7628 - mean_squared_error: 113.76 - 0s 24us/step - loss: 84.8424 - mean_squared_error: 84.8424\n",
      "Epoch 970/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.1231 - mean_squared_error: 85.1231\n",
      "Epoch 971/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 85.0429 - mean_squared_error: 85.0429\n",
      "Epoch 972/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.6192 - mean_squared_error: 85.6192\n",
      "Epoch 973/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8049 - mean_squared_error: 84.8049\n",
      "Epoch 974/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.9590 - mean_squared_error: 84.9590\n",
      "Epoch 975/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.0104 - mean_squared_error: 85.0104\n",
      "Epoch 976/1000\n",
      "506/506 [==============================] - 0s 25us/step - loss: 85.9024 - mean_squared_error: 85.9024\n",
      "Epoch 977/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 85.4606 - mean_squared_error: 85.4606\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 0s 22us/step - loss: 85.7217 - mean_squared_error: 85.7217\n",
      "Epoch 979/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.3145 - mean_squared_error: 85.3145\n",
      "Epoch 980/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.0362 - mean_squared_error: 85.0362\n",
      "Epoch 981/1000\n",
      "506/506 [==============================] - 0s 23us/step - loss: 84.8591 - mean_squared_error: 84.8591\n",
      "Epoch 982/1000\n",
      "506/506 [==============================] - 0s 22us/step - loss: 84.8259 - mean_squared_error: 84.8259\n",
      "Epoch 983/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.5416 - mean_squared_error: 85.5416\n",
      "Epoch 984/1000\n",
      "506/506 [==============================] - 0s 21us/step - loss: 85.4081 - mean_squared_error: 85.4081\n",
      "Epoch 985/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.1637 - mean_squared_error: 85.1637\n",
      "Epoch 986/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.7837 - mean_squared_error: 84.7837\n",
      "Epoch 987/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.8402 - mean_squared_error: 84.8402\n",
      "Epoch 988/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.9000 - mean_squared_error: 85.9000\n",
      "Epoch 989/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.3407 - mean_squared_error: 84.3407\n",
      "Epoch 990/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.6426 - mean_squared_error: 85.6426\n",
      "Epoch 991/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.2127 - mean_squared_error: 85.2127\n",
      "Epoch 992/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 85.5286 - mean_squared_error: 85.5286\n",
      "Epoch 993/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 86.5192 - mean_squared_error: 86.5192\n",
      "Epoch 994/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.3256 - mean_squared_error: 84.3256\n",
      "Epoch 995/1000\n",
      "506/506 [==============================] - 0s 19us/step - loss: 86.1115 - mean_squared_error: 86.1115\n",
      "Epoch 996/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 85.9161 - mean_squared_error: 85.9161\n",
      "Epoch 997/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 84.7159 - mean_squared_error: 84.7159\n",
      "Epoch 998/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 84.9389 - mean_squared_error: 84.9389\n",
      "Epoch 999/1000\n",
      "506/506 [==============================] - 0s 18us/step - loss: 84.9689 - mean_squared_error: 84.9689\n",
      "Epoch 1000/1000\n",
      "506/506 [==============================] - 0s 20us/step - loss: 85.0239 - mean_squared_error: 85.0239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a30671278>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_, y_, epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1 (default, Dec 14 2018, 13:28:58) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
